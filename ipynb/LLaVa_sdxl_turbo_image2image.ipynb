{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7bed34-8b0f-4a14-9682-ecfa8624ec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.16\r\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3881a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current default GPU index: 5\n",
      "Current default GPU name: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(5)\n",
    "if torch.cuda.is_available():\n",
    "    current_gpu = torch.cuda.current_device()\n",
    "    print(f\"Current default GPU index: {current_gpu}\")\n",
    "    print(f\"Current default GPU name: {torch.cuda.get_device_name(current_gpu)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535be0ec-7017-4b24-8bba-1bc38c66b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'feature_extractor': [None, None], 'image_encoder': [None, None]} were passed to StableDiffusionXLImg2ImgPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'feature_extractor': [None, None], 'image_encoder': [None, None]} are not expected by StableDiffusionXLImg2ImgPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b1c81a18aa4e96a133d9e2f95aaf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'reverse_transformer_layers_per_block': None} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionXLImg2ImgPipeline {\n",
       "  \"_class_name\": \"StableDiffusionXLImg2ImgPipeline\",\n",
       "  \"_diffusers_version\": \"0.21.4\",\n",
       "  \"_name_or_path\": \"stabilityai/sdxl-turbo\",\n",
       "  \"force_zeros_for_empty_prompt\": true,\n",
       "  \"requires_aesthetics_score\": false,\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"EulerAncestralDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6fe7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def display_images_side_by_side(image_paths, captions):\n",
    "    # Number of images\n",
    "    n = len(image_paths)\n",
    "    \n",
    "    # Set up the figure with subplots\n",
    "    fig, axes = plt.subplots(1, n, figsize=(4, 2))  # Adjust figure size as needed\n",
    "    \n",
    "    # Loop through images, their axes, and captions\n",
    "    for ax, img_path, caption in zip(axes, image_paths, captions):\n",
    "        # Load and display the image\n",
    "        img = mpimg.imread(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')  # Turn off axis\n",
    "        \n",
    "        # Set the caption\n",
    "        ax.set_title(caption, fontsize=10, pad=10)  # Adjust font size and padding as needed\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece21fe",
   "metadata": {},
   "source": [
    "## image generation with sdxl_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4cc4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "import torchvision\n",
    "\n",
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader, ReplayDataLoader\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark, \\\n",
    "                                            tensors_benchmark, paths_benchmark\n",
    "\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, \\\n",
    "    WandBLogger, TextLogger, TensorboardLogger\n",
    "\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics\n",
    "\n",
    "from avalanche.training.plugins.checkpoint import CheckpointPlugin, \\\n",
    "    FileSystemCheckpointStorage\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "from types import SimpleNamespace\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "\n",
    "# all imports\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torch import cat, Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset, ConcatDataset, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim.lr_scheduler # ?\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, CenterCrop, RandomHorizontalFlip, Resize\n",
    "from torchvision.transforms.functional import center_crop\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45d08336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b973f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR100(root='data', train=True,\n",
    "                                         download=True)\n",
    "\n",
    "name_list = trainset.classes\n",
    "\n",
    "integer_to_name = {i: name for i, name in enumerate(name_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b059e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitCIFAR100(n_experiences=20,\n",
    "                          seed = 41,             \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fbf9b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36, 0, 54, 5, 20],\n",
       " [22, 45, 13, 83, 19],\n",
       " [26, 73, 16, 62, 33],\n",
       " [34, 98, 24, 74, 53],\n",
       " [10, 94, 51, 4, 32],\n",
       " [38, 81, 50, 40, 41],\n",
       " [30, 89, 69, 64, 21],\n",
       " [84, 14, 88, 49, 68],\n",
       " [6, 80, 57, 65, 46],\n",
       " [9, 91, 48, 72, 31],\n",
       " [76, 7, 47, 8, 1],\n",
       " [61, 75, 63, 18, 86],\n",
       " [59, 70, 43, 85, 95],\n",
       " [27, 93, 35, 25, 82],\n",
       " [44, 56, 67, 66, 37],\n",
       " [60, 11, 2, 78, 52],\n",
       " [97, 39, 55, 3, 99],\n",
       " [29, 71, 23, 28, 90],\n",
       " [87, 15, 92, 17, 77],\n",
       " [12, 42, 96, 79, 58]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = benchmark.classes_order\n",
    "order_list = [orders[x:x+5] for x in range(0, len(orders), 5)]\n",
    "order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b0d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_sample = [order[0:3] for order in order_list]\n",
    "classname_list = []\n",
    "label_list = []\n",
    "classname_list_sep = []\n",
    "for order_l in order_sample:\n",
    "    label_list.append(order_l)\n",
    "    cur_classname = [integer_to_name[i] for i in order_l]\n",
    "    classname_list.append(cur_classname)\n",
    "classname_list_sep = [item for lists in classname_list for item in lists]\n",
    "label_list_sep = [item for lists in label_list for item in lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d400d4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fac3d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts_list = [\n",
    "#         \"A black and white image of [concept] highlighting dramatic contrasts.\",\n",
    "#         \"A minimalist image of [concept] using clean lines and muted colors.\",\n",
    "#         \"A photo of [concept] in analogous colors.\",\n",
    "#         \"A photo of [concept] in complementary colors.\",\n",
    "#         \"A photo of [concept] in earth tones.\",\n",
    "#         \"A photo of [concept] in neutral tones.\",\n",
    "#         \"This is an image of the [concept].\",\n",
    "#         \"A realistic image of [concept].\",\n",
    "#         \"A vintage photograph of [concept] with a warm, faded aesthetic.\",\n",
    "#         \"A high-resolution photo of [concept] capturing fine details.\"\n",
    "#     ]\n",
    "# len(prompts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fce296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def extract_prompts_fromtxts(file_path):\n",
    "    prompts = []  # List to hold the prompts\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip() != 'USER':  # Ignore lines that are just 'USER'\n",
    "                # Split the line at the first colon and strip whitespace from the prompt\n",
    "                parts = line.split(':', 1)\n",
    "                if len(parts) > 1:\n",
    "                    prompt = parts[1].strip()\n",
    "                    prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "\n",
    "def create_sdxl_data_fixed_prompts_randommultiple(class_dict, image_size, prompt_file_dict, generator_seed, num_image_replay=50, folder_name=\"/content/sd_images\"):\n",
    "    # Create the folder if it doesn't exist\n",
    "    random.seed(42)\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "\n",
    "        # Check how many images already exist for the class\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{id}.txt\")\n",
    "        current_prompt_list = extract_prompts_fromtxts(prompt_file_path)\n",
    "        \n",
    "        indices = [random.randint(0, len(current_prompt_list)-1) for _ in range(num_image_replay)]\n",
    "        current_prompt_list = [current_prompt_list[item] for item in indices]\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                print(prompt)\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt, generator = generator_seed, num_inference_steps=1, guidance_scale=1.0).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")\n",
    "\n",
    "\n",
    "def create_sdxl_data_fixed_prompts(class_dict, image_size, prompt_file_dict, generator_seed, num_image_replay=50, folder_name=\"/content/sd_images\"):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "\n",
    "        # Check how many images already exist for the class\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{id}.txt\")\n",
    "        current_prompt_list = extract_prompts_fromtxts(prompt_file_path)\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                print(prompt)\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=1.0).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")\n",
    "                \n",
    "                \n",
    "                \n",
    "def create_sdxl_data_fixed_prompts_randommultiple_img2img(class_dict, image_size, prompt_file_dict, startimage_file_path,\n",
    "                                                          generator_seed, num_image_replay=50, folder_name=\"/content/sd_images\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    not done, todo: provide image list as current_prompt_list\n",
    "    \"\"\"\n",
    "    # Create the folder if it doesn't exist\n",
    "    random.seed(42)\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "\n",
    "        # Check how many images already exist for the class\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{id}.txt\")\n",
    "        current_prompt_list = extract_prompts_fromtxts(prompt_file_path)\n",
    "        \n",
    "        \n",
    "        indices = [random.randint(0, len(current_prompt_list)-1) for _ in range(num_image_replay)]\n",
    "        current_prompt_list = [current_prompt_list[item] for item in indices]\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                print(prompt)\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                starting_image_path = os.path.join(startimage_file_path, image_name)\n",
    "                \n",
    "            \n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt, generator = generator_seed, num_inference_steps=1, guidance_scale=1.0).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf59f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sdxl_data_img2img_matching_image_prompt(class_dict, image_size, prompt_file_dict, startimage_file_path,\n",
    "                                                          generator_seed, num_image_replay=50, folder_name=\"/content/sd_images\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    this is specified to matching pair of lavva prompt and images\n",
    "    \"\"\"\n",
    "    # Create the folder if it doesn't exist\n",
    "    random.seed(42)\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "\n",
    "        # Check how many images already exist for the class\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "        prompt_file_path = os.path.join(prompt_file_dict, f\"class{id}.txt\")\n",
    "        current_prompt_list = extract_prompts_fromtxts(prompt_file_path)\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j, prompt in enumerate(current_prompt_list):\n",
    "                print(prompt)\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                \n",
    "                starting_image_path = os.path.join(startimage_file_path, image_name)\n",
    "                init_image = load_image(starting_image_path).resize((512, 512))\n",
    "\n",
    "            \n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt,image = init_image, \n",
    "                                strength = 0.5, \n",
    "                                num_inference_steps=20, \n",
    "                                generator = generator_seed, guidance_scale=2).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96860e49-5da4-482e-bef6-41a63901fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sdxl_llava_random(class_dict, image_size, generator_seed, num_image_replay=50, prompt_folder = \"saved_data/llava_saved_data_310/llava_prompt_50\", folder_name=\"/content/sd_images\"):\n",
    "    random.seed(42)\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "\n",
    "        # Check how many images already exist for the class\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "\n",
    "        indices = [random.randint(0, 9) for _ in range(num_image_replay)]  # Assuming there are 10 prompts\n",
    "        prompts = generate_prompts(class_name, indices)\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j, prompt in enumerate(prompts):\n",
    "                print(prompt)\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=1.0).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a53f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def generate_prompts(concept, indices):\n",
    "    prompts_list = [\n",
    "        \"A black and white image of a real [concept] highlighting dramatic contrasts.\",\n",
    "        \"A minimalist image of a real [concept] using clean lines and muted colors.\",\n",
    "        \"A photo of a real [concept] in analogous colors.\",\n",
    "        \"A photo of a real [concept] in complementary colors.\",\n",
    "        \"A photo of a real [concept] in earth tones.\",\n",
    "        \"A photo of a real [concept] in neutral tones.\",\n",
    "        \"This is an image of the [concept].\",\n",
    "        \"A realistic image of a real [concept].\",\n",
    "        \"A vintage photograph of a real [concept] with a warm, faded aesthetic.\",\n",
    "        \"A high-resolution photo of a real [concept] capturing fine details.\"\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Replace [concept] with the actual concept name\n",
    "    prompt = [prompts_list[item] for item in indices]\n",
    "    \n",
    "    return [pt.replace(\"[concept]\", concept) for pt in prompt]\n",
    "\n",
    "def create_sdxl_data(class_dict, image_size, generator_seed, num_image_replay=50, folder_name=\"/content/sd_images\"):\n",
    "    random.seed(42)\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id, class_name in class_dict.items():\n",
    "        print(\"Generating images for class \" + str(id) + \": \" + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, f\"class{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "\n",
    "        # Check how many images already exist for the class\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "\n",
    "        indices = [random.randint(0, 9) for _ in range(num_image_replay)]  # Assuming there are 10 prompts\n",
    "        prompts = generate_prompts(class_name, indices)\n",
    "\n",
    "        # Generate the new images\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j, prompt in enumerate(prompts):\n",
    "                print(prompt)\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "                new_image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=1.0).images[0]\n",
    "                resized_image = new_image.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baf7f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sdxl_data_baseprompt(class_dict, image_size, generator_seed, num_image_replay = 50, folder_name =  \"/content/sd_images\"):\n",
    "\n",
    "    # Create the folder\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for id in class_dict:\n",
    "        class_name = class_dict[id]\n",
    "        print(\"generating images of class \" + str(id) + class_name)\n",
    "\n",
    "        class_file_path = os.path.join(folder_name, \"class\" + f\"{id}.txt\")\n",
    "        existing_images_count = 0\n",
    "        if os.path.exists(class_file_path):\n",
    "            with open(class_file_path, \"r\") as file:\n",
    "                # existing_images = file.readlines()\n",
    "                existing_images_count = len(file.readlines())\n",
    "            num_images_to_generate = num_image_replay - existing_images_count\n",
    "            \n",
    "            if existing_images_count >= num_image_replay:\n",
    "                print(f\"Class {class_name} already contains {num_image_replay} images. Moving to the next class.\")\n",
    "                continue  # Move to the next class if enough images already exist\n",
    "        \n",
    "        prompt =  \"An image of a real \" + class_name\n",
    "        with open(class_file_path, \"a\") as file:\n",
    "            for j in range(existing_images_count, num_image_replay):\n",
    "                image_name = class_name + f\"{j}.png\"\n",
    "                image_path = os.path.join(folder_name, image_name)\n",
    "\n",
    "                # generate image from stable diffusion\n",
    "                re = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=1.0).images[0]\n",
    "\n",
    "                # Resize the image\n",
    "                resized_image = re.resize(image_size)\n",
    "\n",
    "                resized_image.save(image_path)\n",
    "\n",
    "                file.write(f\"{image_path} {id}\\n\")\n",
    "\n",
    "                print(f\"Generated image {image_name} for class {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79226b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_integer_to_name = {key: integer_to_name[key] for key in label_list_sep if key in integer_to_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6114085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{36: 'hamster',\n",
       " 0: 'apple',\n",
       " 54: 'orchid',\n",
       " 22: 'clock',\n",
       " 45: 'lobster',\n",
       " 13: 'bus',\n",
       " 26: 'crab',\n",
       " 73: 'shark',\n",
       " 16: 'can',\n",
       " 34: 'fox',\n",
       " 98: 'woman',\n",
       " 24: 'cockroach',\n",
       " 10: 'bowl',\n",
       " 94: 'wardrobe',\n",
       " 51: 'mushroom',\n",
       " 38: 'kangaroo',\n",
       " 81: 'streetcar',\n",
       " 50: 'mouse',\n",
       " 30: 'dolphin',\n",
       " 89: 'tractor',\n",
       " 69: 'rocket',\n",
       " 84: 'table',\n",
       " 14: 'butterfly',\n",
       " 88: 'tiger',\n",
       " 6: 'bee',\n",
       " 80: 'squirrel',\n",
       " 57: 'pear',\n",
       " 9: 'bottle',\n",
       " 91: 'trout',\n",
       " 48: 'motorcycle',\n",
       " 76: 'skyscraper',\n",
       " 7: 'beetle',\n",
       " 47: 'maple_tree',\n",
       " 61: 'plate',\n",
       " 75: 'skunk',\n",
       " 63: 'porcupine',\n",
       " 59: 'pine_tree',\n",
       " 70: 'rose',\n",
       " 43: 'lion',\n",
       " 27: 'crocodile',\n",
       " 93: 'turtle',\n",
       " 35: 'girl',\n",
       " 44: 'lizard',\n",
       " 56: 'palm_tree',\n",
       " 67: 'ray',\n",
       " 60: 'plain',\n",
       " 11: 'boy',\n",
       " 2: 'baby',\n",
       " 97: 'wolf',\n",
       " 39: 'keyboard',\n",
       " 55: 'otter',\n",
       " 29: 'dinosaur',\n",
       " 71: 'sea',\n",
       " 23: 'cloud',\n",
       " 87: 'television',\n",
       " 15: 'camel',\n",
       " 92: 'tulip',\n",
       " 12: 'bridge',\n",
       " 42: 'leopard',\n",
       " 96: 'willow_tree'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_integer_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75030617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747bda14",
   "metadata": {},
   "source": [
    "## mixed data llava multiple generation image2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "# create_sdxl_data_fixed_prompts_randommultiple(integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=50, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')\n",
    "\n",
    "create_sdxl_data_img2img_matching_image_prompt(integer_to_name, image_size = (32,32),\n",
    "                                               prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/',\n",
    "                                               startimage_file_path = 'saved_data/llava_saved_data_310/cifar_50/',\n",
    "                                               generator_seed = generator1, num_image_replay=50, \n",
    "                                               folder_name='saved_data/sd_turbo_i2i_50all_step10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9cf1d",
   "metadata": {},
   "source": [
    "## mixed data llava multiple generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54324ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "create_sdxl_data_fixed_prompts_randommultiple(specific_integer_to_name, image_size = (32,32), prompt_file_dict = 'saved_data/llava_saved_data_310/llava_prompt_50/', generator_seed = generator1, num_image_replay=500, folder_name='saved_data/sd_turbo_500images_llava_firstthreeclasses/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fece347",
   "metadata": {},
   "source": [
    "## diverse prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(41)\n",
    "create_sdxl_data(specific_integer_to_name, image_size = (32,32), generator_seed = generator1, num_image_replay=500, folder_name='saved_data/sd_turbo_500images/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b976d",
   "metadata": {},
   "source": [
    "## base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0769c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator(device=\"cuda\").manual_seed(41)\n",
    "create_sdxl_data_baseprompt(specific_integer_to_name, image_size = (32,32), generator_seed = generator1, num_image_replay=500, folder_name='saved_data/sd_turbo_500images_baseprompt/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99caaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_txt_files(folder_path):\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"The specified folder does not exist.\")\n",
    "        return 0\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter and count files that end with .txt\n",
    "    txt_files_count = sum(1 for file in files if file.endswith('.txt'))\n",
    "    \n",
    "    return txt_files_count\n",
    "\n",
    "# Specify the folder path here\n",
    "folder_path = 'saved_data/sd_turbo_i2i_50all'\n",
    "\n",
    "# Call the function and print the result\n",
    "count = count_txt_files(folder_path)\n",
    "print(f\"There are {count} .txt files in the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_print_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()  # Read all lines in the file\n",
    "            print(len(lines))\n",
    "            for line in lines:\n",
    "                print(line.strip())  # Print each line, stripping newline characters\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {file_path} does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'saved_data/cifar_train500/class36.txt'\n",
    "read_and_print_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0dd39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
