{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnAseRU021TN"
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current default GPU index: 1\n",
      "Current default GPU name: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "if torch.cuda.is_available():\n",
    "    current_gpu = torch.cuda.current_device()\n",
    "    print(f\"Current default GPU index: {current_gpu}\")\n",
    "    print(f\"Current default GPU name: {torch.cuda.get_device_name(current_gpu)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "72UHkOSf3BhU"
   },
   "outputs": [],
   "source": [
    "# all imports\n",
    "\n",
    "# buffer\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import (\n",
    "    Any,\n",
    "    Dict,\n",
    "    Generic,\n",
    "    Optional,\n",
    "    List,\n",
    "    TYPE_CHECKING,\n",
    "    Set,\n",
    "    TypeVar,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from numpy import inf\n",
    "from torch import cat, Tensor\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from avalanche.benchmarks.utils import (\n",
    "    classification_subset,\n",
    "    AvalancheDataset,\n",
    ")\n",
    "from avalanche.models import FeatureExtractorBackbone\n",
    "# from ..benchmarks.utils.utils import concat_datasets\n",
    "from avalanche.benchmarks.utils import concat_datasets\n",
    "from avalanche.training.storage_policy import ReservoirSamplingBuffer, BalancedExemplarsBuffer, ClassBalancedBuffer\n",
    "# from avalanche.training.storage_policy\n",
    "if TYPE_CHECKING:\n",
    "    from .templates import SupervisedTemplate, BaseSGDTemplate\n",
    "\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "from avalanche.training.plugins import SupervisedPlugin\n",
    "from typing import Optional, TYPE_CHECKING\n",
    "\n",
    "from avalanche.benchmarks.utils import concat_classification_datasets\n",
    "from avalanche.training.plugins.strategy_plugin import SupervisedPlugin\n",
    "from avalanche.training.storage_policy import (\n",
    "    ExemplarsBuffer,\n",
    "    ExperienceBalancedBuffer,\n",
    ")\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from avalanche.training.templates import SupervisedTemplate\n",
    "\n",
    "\n",
    "# dataset\n",
    "from avalanche.benchmarks import SplitMNIST, SplitCIFAR100\n",
    "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader, ReplayDataLoader\n",
    "\n",
    "from torch.utils.data.dataset import Subset, ConcatDataset, TensorDataset\n",
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "import torch.optim.lr_scheduler # ?\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark, \\\n",
    "                                            tensors_benchmark, paths_benchmark\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, CenterCrop\n",
    "from torchvision.transforms.functional import center_crop\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, RandomHorizontalFlip, Resize\n",
    "import os\n",
    "\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, \\\n",
    "    WandBLogger, TextLogger\n",
    "\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics\n",
    "\n",
    "from avalanche.training.plugins.checkpoint import CheckpointPlugin, \\\n",
    "    FileSystemCheckpointStorage\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "# training\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "\n",
    "# strategies\n",
    "from avalanche.models import SimpleMLP\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# training\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "\n",
    "# strategies\n",
    "from avalanche.models import SimpleMLP\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz-Clnts3NzX"
   },
   "source": [
    "# Replay Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A4bGw8I_3NkB"
   },
   "outputs": [],
   "source": [
    "# from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "# from avalanche.training.plugins import SupervisedPlugin\n",
    "\n",
    "# class CustomReplay(SupervisedPlugin):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         mem_size: int = 200,\n",
    "#         batch_size: Optional[int] = None,\n",
    "#         batch_size_mem: Optional[int] = None,\n",
    "#         task_balanced_dataloader: bool = False,\n",
    "#         storage_policy: Optional[\"ExemplarsBuffer\"] = None,\n",
    "#         # The policy that controls how to add new exemplars in memory\n",
    "#                         #\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.mem_size = mem_size\n",
    "#         self.batch_size = batch_size\n",
    "#         self.batch_size_mem = batch_size_mem\n",
    "#         self.task_balanced_dataloader = task_balanced_dataloader\n",
    "\n",
    "#         self.storage_policy = storage_policy\n",
    "#         assert storage_policy.max_size == self.mem_size\n",
    "\n",
    "#     def before_training_exp(self,\n",
    "#                             strategy: \"SupervisedTemplate\",\n",
    "#                             num_workers: int = 0,\n",
    "#                             shuffle: bool = True,\n",
    "#                             **kwargs):\n",
    "#         \"\"\" Here we set the dataloader. create batch with examples from both\n",
    "#         training data and external memory\"\"\"\n",
    "#         if len(self.storage_policy.buffer) == 0:\n",
    "#             # first experience. We don't use the buffer, no need to change\n",
    "#             # the dataloader.\n",
    "#             return\n",
    "\n",
    "#         # replay dataloader samples mini-batches from the memory and current\n",
    "#         # data separately and combines them together.\n",
    "#         print(\"Override the dataloader.\")\n",
    "#         strategy.dataloader = ReplayDataLoader(\n",
    "#             strategy.adapted_dataset,\n",
    "#             self.storage_policy.buffer,\n",
    "#             oversample_small_tasks=True,\n",
    "#             num_workers=num_workers,\n",
    "#             batch_size=strategy.train_mb_size,\n",
    "#             shuffle=shuffle)\n",
    "\n",
    "#     def after_training_exp(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "#         \"\"\" We update the buffer after the experience.\n",
    "#             You can use a different callback to update the buffer in a different place\n",
    "#         \"\"\"\n",
    "#         print(\"Buffer update.\")\n",
    "#         self.storage_policy.update(strategy, **kwargs)\n",
    "\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "from avalanche.training.plugins import SupervisedPlugin\n",
    "from typing import Optional, TYPE_CHECKING\n",
    "\n",
    "from avalanche.benchmarks.utils import concat_classification_datasets\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "from avalanche.training.plugins.strategy_plugin import SupervisedPlugin\n",
    "from avalanche.training.storage_policy import (\n",
    "    ExemplarsBuffer,\n",
    "    ExperienceBalancedBuffer,\n",
    ")\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from avalanche.training.templates import SupervisedTemplate\n",
    "\n",
    "import random\n",
    "def sample_Avadataset(dataset, percentage= 0.1):\n",
    "    \"\"\"random sample in certain percentage, percentage should be float\"\"\"\n",
    "#     random.seed(41)\n",
    "    torch.manual_seed(41)\n",
    "    data_len = len(dataset)\n",
    "#     indices = list(range(data_len))\n",
    "    indices = torch.randperm(data_len).tolist()\n",
    "#     random.shuffle(indices)\n",
    "    sample_num = int(data_len * percentage)\n",
    "#     sampled_indices = random.sample(indices, sample_num)\n",
    "#     new_buffer_data = dataset.subset(sampled_indices)\n",
    "    sampled_indices = indices[:sample_num]  # Select the first 'sample_num' indices\n",
    "    new_buffer_data = dataset.subset(sampled_indices)\n",
    "\n",
    "    return new_buffer_data\n",
    "\n",
    "\n",
    "\n",
    "class CustomReplay(SupervisedPlugin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mem_size: int = 200,\n",
    "        batch_size: Optional[int] = None,\n",
    "        batch_size_mem: Optional[int] = None,\n",
    "        task_balanced_dataloader: bool = False,\n",
    "        storage_policy: Optional[\"ExemplarsBuffer\"] = None,\n",
    "        # The policy that controls how to add new exemplars in memory\n",
    "                        #\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mem_size = mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_mem = batch_size_mem\n",
    "        self.task_balanced_dataloader = task_balanced_dataloader\n",
    "\n",
    "        self.storage_policy = storage_policy\n",
    "        assert storage_policy.max_size == self.mem_size\n",
    "\n",
    "\n",
    "\n",
    "    def before_training_exp(self,\n",
    "                            strategy: \"SupervisedTemplate\",\n",
    "                            num_workers: int = 0,\n",
    "                            shuffle: bool = True,\n",
    "                            **kwargs):\n",
    "        \"\"\" Here we set the dataloader. create batch with examples from both\n",
    "        training data and external memory\"\"\"\n",
    "        if len(self.storage_policy.buffer) == 0:\n",
    "            return\n",
    "\n",
    "        # replay dataloader samples mini-batches from the memory and current\n",
    "        # data separately and combines them together.\n",
    "        print(\"Override the dataloader.\")\n",
    "\n",
    "        buffer_size = len(self.storage_policy.buffer)\n",
    "        print(\"buffer size: \" + str(buffer_size))\n",
    "        num_class = len(self.storage_policy.buffer_datasets)\n",
    "        print(\"current class number in replay buffer: \" + str(num_class))\n",
    "        # for item in self.storage_policy.buffer:\n",
    "        # tempory_buffer = AvalancheDataset([])\n",
    "\n",
    "        tempory_buffer = []\n",
    "\n",
    "        for i, dataset in enumerate(self.storage_policy.buffer_datasets):\n",
    "            sub_data = sample_Avadataset(dataset)\n",
    "            if i == 0:\n",
    "                tempory_buffer = sub_data\n",
    "            else:\n",
    "                tempory_buffer = tempory_buffer.concat(sub_data)\n",
    "\n",
    "\n",
    "        # buffer = [sample_Avadataset(dataset) for dataset in self.storage_policy.buffer_datasets]\n",
    "        strategy.dataloader = ReplayDataLoader(\n",
    "            strategy.adapted_dataset,\n",
    "            # self.storage_policy.buffer,\n",
    "            tempory_buffer,\n",
    "            num_workers=num_workers,\n",
    "            batch_size=strategy.train_mb_size,\n",
    "            shuffle=shuffle)\n",
    "        # for x, y, t in dl:\n",
    "        #     print(t.tolist())\n",
    "        #     print(len(t.tolist()))\n",
    "\n",
    "    def after_training_exp(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "        \"\"\" We update the buffer after the experience.\n",
    "            You can use a different callback to update the buffer in a different place\n",
    "        \"\"\"\n",
    "        print(\"Buffer update.\")\n",
    "        self.storage_policy.update(strategy, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ5u-Q7q8ICA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SkzGD50u9ort"
   },
   "outputs": [],
   "source": [
    "# self.storage_policy.update(strategy, **kwargs)-> parametric buffer update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ul3W9r9SSBOm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Subset, ConcatDataset, TensorDataset\n",
    "\n",
    "class NewParametricBuffer(BalancedExemplarsBuffer):\n",
    "    \"\"\"Stores samples for replay using a custom selection strategy and\n",
    "    grouping.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_size: int,\n",
    "        groupby=None,\n",
    "        selection_strategy: Optional[\"ExemplarsSelectionStrategy\"] = None,\n",
    "    ):\n",
    "        \"\"\"Init.\n",
    "        :param max_size: The max capacity of the replay memory.\n",
    "        :param groupby: Grouping mechanism. One of {None, 'class', 'task',\n",
    "            'experience'}.\n",
    "        :param selection_strategy: The strategy used to select exemplars to\n",
    "            keep in memory when cutting it off.\n",
    "        \"\"\"\n",
    "        super().__init__(max_size)\n",
    "        assert groupby in {None, \"task\", \"class\", \"experience\"}, (\n",
    "            \"Unknown grouping scheme. Must be one of {None, 'task', \"\n",
    "            \"'class', 'experience'}\"\n",
    "        )\n",
    "        self.groupby = groupby\n",
    "        ss = selection_strategy or RandomExemplarsSelectionStrategy()\n",
    "        self.selection_strategy = ss\n",
    "        self.seen_groups: Set[int] = set()\n",
    "        self._curr_strategy = None\n",
    "\n",
    "\n",
    "    def update(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "        assert strategy.experience is not None\n",
    "        new_data: AvalancheDataset = strategy.experience.dataset\n",
    "        new_groups = self._make_groups(strategy, new_data)\n",
    "        self.seen_groups.update(new_groups.keys())\n",
    "\n",
    "        # associate lengths to classes\n",
    "        lens = self.get_group_lengths(len(self.seen_groups))\n",
    "        group_to_len = {}\n",
    "        for group_id, ll in zip(self.seen_groups, lens):\n",
    "            group_to_len[group_id] = ll\n",
    "\n",
    "        # update buffers with new data\n",
    "        for group_id, new_data_g in new_groups.items():\n",
    "            ll = group_to_len[group_id]\n",
    "            if group_id in self.buffer_groups:\n",
    "                old_buffer_g = self.buffer_groups[group_id]\n",
    "                old_buffer_g.update_from_dataset(strategy, new_data_g)\n",
    "                old_buffer_g.resize(strategy, ll)\n",
    "            else:\n",
    "                new_buffer = _ParametricSingleBuffer(ll, self.selection_strategy)\n",
    "                new_buffer.update_from_dataset(strategy, new_data_g)\n",
    "                self.buffer_groups[group_id] = new_buffer\n",
    "\n",
    "        # resize buffers\n",
    "        for group_id, class_buf in self.buffer_groups.items():\n",
    "            self.buffer_groups[group_id].resize(strategy, group_to_len[group_id])\n",
    "\n",
    "    def _make_groups(\n",
    "        self, strategy, data: AvalancheDataset\n",
    "    ) -> Dict[int, AvalancheDataset]:\n",
    "        \"\"\"Split the data by group according to `self.groupby`.\"\"\"\n",
    "        # if self.groupby is None:\n",
    "        #     return {0: data}\n",
    "        # elif self.groupby == \"task\":\n",
    "        #     return self._split_by_task(data)\n",
    "        # elif self.groupby == \"experience\":\n",
    "        #     return self._split_by_experience(strategy, data)\n",
    "        # elif self.groupby == \"class\":\n",
    "        return self._split_by_class(data)\n",
    "        # else:\n",
    "        #     assert False, \"Invalid groupby key. Should never get here.\"\n",
    "\n",
    "    def _split_by_class(self, data: AvalancheDataset) -> Dict[int, AvalancheDataset]:\n",
    "        # Get sample idxs per class\n",
    "        cl_idxs: Dict[int, List[int]] = defaultdict(list)\n",
    "        targets = getattr(data, \"targets\")\n",
    "        for idx, target in enumerate(targets):\n",
    "            target = int(target)\n",
    "            cl_idxs[target].append(idx)\n",
    "\n",
    "        # Make AvalancheSubset per class\n",
    "        new_groups: Dict[int, AvalancheDataset] = {}\n",
    "        for c, c_idxs in cl_idxs.items():\n",
    "            new_groups[c] = classification_subset(data, indices=c_idxs)\n",
    "        return new_groups\n",
    "\n",
    "    # def _split_by_experience(\n",
    "    #     self, strategy, data: AvalancheDataset\n",
    "    # ) -> Dict[int, AvalancheDataset]:\n",
    "    #     exp_id = strategy.clock.train_exp_counter + 1\n",
    "    #     return {exp_id: data}\n",
    "\n",
    "    # def _split_by_task(self, data: AvalancheDataset) -> Dict[int, AvalancheDataset]:\n",
    "    #     new_groups = {}\n",
    "    #     task_set = getattr(data, \"task_set\")\n",
    "    #     for task_id in task_set:\n",
    "    #         new_groups[task_id] = task_set[task_id]\n",
    "    #     return new_groups\n",
    "\n",
    "\n",
    "\n",
    "class _ParametricSingleBuffer(ExemplarsBuffer):\n",
    "    \"\"\"A buffer that stores samples for replay using a custom selection\n",
    "    strategy.\n",
    "\n",
    "    This is a private class. Use `ParametricBalancedBuffer` with\n",
    "    `groupby=None` to get the same behavior.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_size: int,\n",
    "        selection_strategy: Optional[\"ExemplarsSelectionStrategy\"] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param max_size: The max capacity of the replay memory.\n",
    "        :param selection_strategy: The strategy used to select exemplars to\n",
    "                                   keep in memory when cutting it off.\n",
    "        \"\"\"\n",
    "        super().__init__(max_size)\n",
    "        ss = selection_strategy or RandomExemplarsSelectionStrategy()\n",
    "        self.selection_strategy = ss\n",
    "        self._curr_strategy = None\n",
    "\n",
    "    def update(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "        assert strategy.experience is not None\n",
    "        new_data = strategy.experience.dataset\n",
    "        self.update_from_dataset(strategy, new_data)\n",
    "\n",
    "    def update_from_dataset(self, strategy, new_data):\n",
    "        # print(new_data[1])\n",
    "        data_len = len(new_data)\n",
    "        indices = list(range(data_len))\n",
    "        random.shuffle(indices)\n",
    "        sample_num = int(data_len * 0.2)\n",
    "        sampled_indices = random.sample(indices, sample_num)\n",
    "        # new_buffer_data = new_data[:sample_num]\n",
    "        # new_buffer_data = Subset(new_data, sampled_indices)\n",
    "        new_buffer_data = new_data.subset(sampled_indices)\n",
    "\n",
    "        self.buffer = self.buffer.concat(new_buffer_data)\n",
    "        self.resize(strategy, self.max_size)\n",
    "\n",
    "    def resize(self, strategy, new_size: int):\n",
    "        self.max_size = new_size\n",
    "        idxs = self.selection_strategy.make_sorted_indices(\n",
    "            strategy=strategy, data=self.buffer\n",
    "        )\n",
    "        self.buffer = self.buffer.subset(idxs[: self.max_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ljxpNjOtdfhj"
   },
   "outputs": [],
   "source": [
    "# def data\n",
    "#     total_indices = len(data)\n",
    "#     num_samples = int(total_indices * self.percentage)  # Calculate number of samples based on percentage\n",
    "\n",
    "#     indices = list(range(total_indices))  # Generate a list of all indices\n",
    "#     random.shuffle(indices)\n",
    "\n",
    "#     sampled_indices = random.sample(indices, num_samples)  # Randomly sample indices\n",
    "\n",
    "#     return sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yy2JCYtzR2-O"
   },
   "outputs": [],
   "source": [
    "# class ParametricBuffer(BalancedExemplarsBuffer):\n",
    "#     def __init__(self, max_size: int, percent_samples_per_class: float, groupby='class', selection_strategy: Optional[\"ExemplarsSelectionStrategy\"] = None):\n",
    "#         \"\"\"\n",
    "#         :param percent_samples_per_class: The percentage of samples to keep from each class after an update.\n",
    "#         \"\"\"\n",
    "#         super().__init__(max_size, groupby, selection_strategy)\n",
    "#         self.percent_samples_per_class = percent_samples_per_class\n",
    "\n",
    "#     def update(self, strategy: \"SupervisedTemplate\", **kwargs):\n",
    "#         super().update(strategy, **kwargs)  # Assuming super().update does the necessary updates\n",
    "#         self._adjust_buffer_to_percent()\n",
    "\n",
    "#     def _adjust_buffer_to_percent(self):\n",
    "#         \"\"\"\n",
    "#         Adjusts the buffer to retain only a specified percentage of examples from each class.\n",
    "#         \"\"\"\n",
    "#         for group_id, buffer_group in self.buffer_groups.items():\n",
    "#             num_samples_to_keep = int(len(buffer_group) * self.percent_samples_per_class)\n",
    "#             if len(buffer_group) > num_samples_to_keep:\n",
    "#                 selected_indices = np.random.choice(len(buffer_group), num_samples_to_keep, replace=False)\n",
    "#                 self.buffer_groups[group_id] = buffer_group.subset(selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCegSFyEeR8B",
    "outputId": "11fbd490-1838-48d5-db07-1dfbf5751562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "random.sample(l, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VUd1jnlL4vV"
   },
   "source": [
    "# Data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZyQi87koaOjd"
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch_pretrained_vit\n",
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "import torch.optim.lr_scheduler # ?\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark, \\\n",
    "                                            tensors_benchmark, paths_benchmark\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, CenterCrop\n",
    "from torchvision.transforms.functional import center_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DkwtwPTByTNd"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, RandomHorizontalFlip, Resize\n",
    "import os\n",
    "# stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "# stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "transform_train = Compose([\n",
    "    Resize(224),\n",
    "    # Resize(384),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    Resize(224),\n",
    "    # Resize(384),\n",
    "    ToTensor(),\n",
    "    Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "# from torchvision.transforms import Resize\n",
    "# transform1 = Compose([\n",
    "#     Resize(224),\n",
    "#     ToTensor()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a5YNVSvRJH6n"
   },
   "outputs": [],
   "source": [
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, \\\n",
    "    WandBLogger, TextLogger\n",
    "# log to Tensorboard\n",
    "tb_logger = TensorboardLogger()\n",
    "\n",
    "# log to text file\n",
    "text_logger = TextLogger(open('logs/method2_replay_real_resample_dino_50epochs.txt', 'a'))\n",
    "\n",
    "# print to stdout\n",
    "interactive_logger = InteractiveLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Qx3UrGFcJH6o"
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics\n",
    "\n",
    "# The evaluation plugin manages the metrics computation.\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "    # forgetting_metrics(experience=True, stream=True),\n",
    "    loggers=[interactive_logger, text_logger, tb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f3UKvdtpc9tL"
   },
   "outputs": [],
   "source": [
    "from avalanche.training.plugins.checkpoint import CheckpointPlugin, \\\n",
    "    FileSystemCheckpointStorage\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRjpqXv9dR9V",
    "outputId": "02f182bd-e6c9-4203-cbaf-c774d486b717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "RNGManager.set_random_seeds(1234)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "checkpoint_plugin = CheckpointPlugin(\n",
    "    FileSystemCheckpointStorage(\n",
    "        directory='./checkpoints/task_cifar',\n",
    "    ),\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "# Load checkpoint (if exists in the given storage)\n",
    "# If it does not exist, strategy will be None and initial_exp will be 0\n",
    "strategy, initial_exp = checkpoint_plugin.load_checkpoint_if_exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jCGd0-QB0yVa"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "\n",
    "# strategies\n",
    "from avalanche.models import SimpleMLP\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QQyaZxLvO_y",
    "outputId": "c5fb67f6-2a24-43a3-a619-b2bdbcadc1af"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "# weights = ResNet18_Weights.DEFAULT\n",
    "# resnet_model = resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /homes/55/enbo/.cache/torch/hub/facebookresearch_dino_main\n",
      "/homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 204900\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# resnet50 = torch.hub.load('ckpt/dino_resnet50_pretrain.pth', 'dino_resnet50')\n",
    "resnet_model = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\n",
    "resnet_model.fc = nn.Identity()\n",
    "\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "\n",
    "# Step 2: Create a new network class with an additional linear layer\n",
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_classes):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.fc = nn.Linear(2048, num_classes)  # New linear layer with trainable weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the pre-trained model\n",
    "        features = self.pretrained_model(x)\n",
    "        # Flatten the output for the linear layer if not already flattened\n",
    "        features = torch.flatten(features, 1)\n",
    "        # Pass features through the new linear layer\n",
    "        output = self.fc(features)\n",
    "        return output\n",
    "\n",
    "# Step 3: Initialize the new network with the desired number of output classes\n",
    "num_classes = 100  # Example: 10 classes for a new classification task\n",
    "resnet_model = CustomNetwork(resnet_model, num_classes)\n",
    "\n",
    "# The only parameters that are trainable are those of the new linear layer\n",
    "trainable_params = sum(p.numel() for p in resnet_model.parameters() if p.requires_grad)\n",
    "print(f'Trainable parameters: {trainable_params}')  # Should print > 0 if the fc layer is correctly set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "upPlxk-6vO_z"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "from avalanche.training import Naive, CWRStar, Replay, GDumb, \\\n",
    "    Cumulative, LwF, GEM, AGEM, EWC, AR1\n",
    "\n",
    "# strategies\n",
    "from avalanche.models import SimpleMLP\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.training.plugins import ReplayPlugin\n",
    "\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GC7OJldpAJ3O",
    "outputId": "2a8f3768-24d1-45c5-93c9-ba76ab08a6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitCIFAR100(n_experiences=20,\n",
    "                          train_transform=transform_train,\n",
    "                          eval_transform = transform_test,\n",
    "                          seed = 41\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ScxqdM155n7",
    "outputId": "451e54fd-8128-423f-d72e-1c3c7e7f2071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 60000, current size: 0\n",
      "Max buffer size: 60000, current size: 2500\n",
      "Max buffer size: 60000, current size: 5000\n",
      "Max buffer size: 60000, current size: 7500\n",
      "Max buffer size: 60000, current size: 10000\n",
      "Max buffer size: 60000, current size: 12500\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=60000,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "    # selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "for i in range(5):\n",
    "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
    "    # print(len(benchmark.train_stream[i]))\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    # print(f\"class targets: {storage_p.buffer.targets}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFWmkWVN7UL-"
   },
   "source": [
    "## change epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lItrmMGx7TSg"
   },
   "outputs": [],
   "source": [
    "storage_p = ParametricBuffer(\n",
    "    max_size=60000,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "    # selection_strategy=RandomExemplarsSelectionStrategy()\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "G-DrjVGL7TSg"
   },
   "outputs": [],
   "source": [
    "cl_strategy = Naive(\n",
    "    resnet_model, torch.optim.SGD(resnet_model.fc.parameters(), lr=0.01, momentum = 0.9),\n",
    "    CrossEntropyLoss(), train_mb_size=32, train_epochs=50, eval_mb_size=16,\n",
    "    # eval_every=500,\n",
    "    device=device,\n",
    "    evaluator=eval_plugin,\n",
    "    plugins=[CustomReplay(mem_size=60000, storage_policy = storage_p)]\n",
    "    )\n",
    "# mem_size: int = 200,\n",
    "        # batch_size: Optional[int] = None,\n",
    "        # batch_size_mem: Optional[int] = None,\n",
    "        # task_balanced_dataloader: bool = False,\n",
    "        # storage_policy: Optional[\"ExemplarsBuffer\"] = None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ep1Rpq-g7TSh",
    "outputId": "b851b612-1ee4-43a3-f8c3-0b5910b91e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience:  0\n",
      "Current Classes:  [0, 36, 5, 20, 54]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  9.54it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4102\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6640\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.00it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6029\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8476\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.39it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4572\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8868\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.33it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4052\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8944\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.40it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3498\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9060\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.06it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3194\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9176\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.11it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2913\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9248\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.70it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2741\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9296\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.54it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2554\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9372\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.19it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2384\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9408\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.05it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2324\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9444\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.27it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2285\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9432\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.07it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2206\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9424\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.49it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2123\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9476\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.16it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1988\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9488\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.34it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1945\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9528\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.13it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1816\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9560\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.52it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1738\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9620\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.98it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1746\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9560\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 13.98it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1844\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9516\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.17it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1703\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9568\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.34it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1658\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9612\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.58it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1641\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9608\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.79it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1555\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9576\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.21it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1541\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9608\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.67it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1566\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9608\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.84it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1489\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9644\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.21it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1493\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9596\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.57it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1436\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9648\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.21it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1380\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9692\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.83it/s]\n",
      "Epoch 30 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1378\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9660\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.46it/s]\n",
      "Epoch 31 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1424\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9628\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.74it/s]\n",
      "Epoch 32 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1302\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.20it/s]\n",
      "Epoch 33 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1265\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9692\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.69it/s]\n",
      "Epoch 34 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1292\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9688\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.88it/s]\n",
      "Epoch 35 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1309\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9680\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.72it/s]\n",
      "Epoch 36 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1262\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9672\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 18.47it/s]\n",
      "Epoch 37 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1278\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9704\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 18.86it/s]\n",
      "Epoch 38 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1218\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9724\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.40it/s]\n",
      "Epoch 39 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1299\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9636\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.71it/s]\n",
      "Epoch 40 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1215\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9688\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.33it/s]\n",
      "Epoch 41 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1119\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9760\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.29it/s]\n",
      "Epoch 42 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1160\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9712\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 13.56it/s]\n",
      "Epoch 43 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1176\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9712\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.21it/s]\n",
      "Epoch 44 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1110\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9736\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.71it/s]\n",
      "Epoch 45 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1055\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9772\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.00it/s]\n",
      "Epoch 46 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1082\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9736\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 13.78it/s]\n",
      "Epoch 47 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1126\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9732\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.02it/s]\n",
      "Epoch 48 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1085\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9748\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 16.35it/s]\n",
      "Epoch 49 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1140\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9720\n",
      "Buffer update.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 20.31it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1348\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9500\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.06it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.8371\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.16it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.2147\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 29.89it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.8092\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.84it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.6169\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.96it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 12.6190\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- Starting eval on experience 6 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 32.61it/s]\n",
      "> Eval on experience 6 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp006 = 12.5194\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.0000\n",
      "-- Starting eval on experience 7 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.34it/s]\n",
      "> Eval on experience 7 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp007 = 12.9636\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.0000\n",
      "-- Starting eval on experience 8 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.22it/s]\n",
      "> Eval on experience 8 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp008 = 13.1387\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.0000\n",
      "-- Starting eval on experience 9 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.34it/s]\n",
      "> Eval on experience 9 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp009 = 12.3333\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.0000\n",
      "-- Starting eval on experience 10 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 31.02it/s]\n",
      "> Eval on experience 10 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp010 = 12.5197\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.0000\n",
      "-- Starting eval on experience 11 (Task 0) from test stream --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 28.06it/s]\n",
      "> Eval on experience 11 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp011 = 12.2923\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.0000\n",
      "-- Starting eval on experience 12 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 28.65it/s]\n",
      "> Eval on experience 12 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp012 = 12.8392\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.0000\n",
      "-- Starting eval on experience 13 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 30.07it/s]\n",
      "> Eval on experience 13 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp013 = 12.9077\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.0000\n",
      "-- Starting eval on experience 14 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 29.56it/s]\n",
      "> Eval on experience 14 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp014 = 12.6873\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.0000\n",
      "-- Starting eval on experience 15 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 28.99it/s]\n",
      "> Eval on experience 15 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp015 = 12.7254\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.0000\n",
      "-- Starting eval on experience 16 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 29.00it/s]\n",
      "> Eval on experience 16 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp016 = 12.5911\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.0000\n",
      "-- Starting eval on experience 17 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 27.79it/s]\n",
      "> Eval on experience 17 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp017 = 12.2481\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.0000\n",
      "-- Starting eval on experience 18 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 28.69it/s]\n",
      "> Eval on experience 18 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp018 = 13.1331\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp018 = 0.0000\n",
      "-- Starting eval on experience 19 (Task 0) from test stream --\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 32/32 [00:01<00:00, 28.40it/s]\n",
      "> Eval on experience 19 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp019 = 12.6980\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp019 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 12.0414\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0475\n",
      "Start of experience:  1\n",
      "Current Classes:  [13, 45, 83, 19, 22]\n",
      "-- >> Start of training phase << --\n",
      "Override the dataloader.\n",
      "buffer size: 2500\n",
      "current class number in replay buffer: 5\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 13.63it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8514\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5775\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.27it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2647\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7782\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.29it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8069\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.25it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6433\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8295\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.36it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5891\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8389\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.59it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5358\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8556\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.76it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5126\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8571\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.76it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4788\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8622\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.39it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4597\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8691\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 15.08it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4512\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8680\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 79/79 [00:05<00:00, 14.71it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4273\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8775\n",
      " 37%|████████████████████████████▋                                                 | 29/79 [00:02<00:03, 14.45it/s]"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "\n",
    "    # train returns a dictionary which contains all the metric values\n",
    "    res = cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    # test also returns a dictionary which contains all the metric values\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXkRIZeKY9Sf"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
